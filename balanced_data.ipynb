{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af27d02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aperçu du dataset original ===\n",
      "   latitude  longitude   TEB_log  REF_BULK_log  CEC_CLAY  GYPSUM_log  \\\n",
      "0  36.74886    6.25409  2.995732      0.970779      53.0    1.960095   \n",
      "1  35.87978    4.44782  3.806662      1.040277      48.0    2.208274   \n",
      "2  35.70751    5.53337  3.806662      1.040277      48.0    2.208274   \n",
      "3  32.27667    3.98647  3.806662      0.996949      71.0    2.028148   \n",
      "4  32.40079    4.00642  3.806662      0.996949      71.0    2.028148   \n",
      "\n",
      "   TEXTURE_SOTER_encoded  ORG_CARBON_log  LCCCODE_encoded  ELEC_COND_log  \\\n",
      "0                    3.0        2.205193              1.0       1.945910   \n",
      "1                    3.0        2.099734              3.0       2.079442   \n",
      "2                    3.0        2.099734             16.0       2.079442   \n",
      "3                    3.0        2.040571             18.0       2.197225   \n",
      "4                    3.0        2.040571              3.0       2.197225   \n",
      "\n",
      "   COARSE  TEXTURE_USDA_encoded  class      tmin      tmax      prec  \\\n",
      "0    11.0                   5.0      1 -1.413339 -2.378421  7.042806   \n",
      "1     5.0                   4.0      1 -1.217517 -1.798088  1.321608   \n",
      "2     5.0                   4.0      1 -2.666088 -2.901592  1.779119   \n",
      "3     3.0                   5.0      1 -0.148714 -0.357337 -0.270135   \n",
      "4     3.0                   5.0      1 -0.134229 -0.420916 -0.251232   \n",
      "\n",
      "   elevation_scaled  \n",
      "0         -1.575026  \n",
      "1          0.608318  \n",
      "2          3.851351  \n",
      "3         -0.345004  \n",
      "4         -0.410976  \n",
      "✔ Dataset final optimisé sauvegardé sous : C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_feature_final.csv\n",
      "=== Nouvelle forme du dataset ===\n",
      "(140165, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. Charger le dataset original ===\n",
    "df = pd.read_csv(r\"C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_final_clean_no_duplicates.csv\")\n",
    "\n",
    "print(\"=== Aperçu du dataset original ===\")\n",
    "print(df.head())\n",
    "\n",
    "# === 2. Supprimer la feature inutile REF_BULK_log ===\n",
    "df = df.drop(columns=[\"REF_BULK_log\"])\n",
    "\n",
    "# === 3. Créer les nouvelles features tmean et trange ===\n",
    "df[\"tmean\"] = (df[\"tmin\"] + df[\"tmax\"]) / 2\n",
    "df[\"trange\"] = df[\"tmax\"] - df[\"tmin\"]\n",
    "\n",
    "# === 4. Supprimer les colonnes redondantes tmin et tmax ===\n",
    "df = df.drop(columns=[\"tmin\", \"tmax\"])\n",
    "\n",
    "# === 5. Sauvegarder le dataset final ===\n",
    "output_file = r\"C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_feature_final.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✔ Dataset final optimisé sauvegardé sous : {output_file}\")\n",
    "print(\"=== Nouvelle forme du dataset ===\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01aba6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalisation terminée. Aperçu :\n",
      "   latitude  longitude   TEB_log  CEC_CLAY  GYPSUM_log  TEXTURE_SOTER_encoded  \\\n",
      "0  1.599941   0.424514 -0.873085 -0.186051   -0.359351               0.414534   \n",
      "1  1.008210  -0.100769  0.326187 -0.472797    0.205265               0.414534   \n",
      "2  0.890917   0.214921  0.326187 -0.472797    0.205265               0.414534   \n",
      "3 -1.445041  -0.234935  0.326187  0.846235   -0.204527               0.414534   \n",
      "4 -1.360532  -0.229133  0.326187  0.846235   -0.204527               0.414534   \n",
      "\n",
      "   ORG_CARBON_log  LCCCODE_encoded  ELEC_COND_log    COARSE  \\\n",
      "0        0.923640        -1.239120      -0.436378  0.537499   \n",
      "1        0.430136        -1.002590       0.023074 -0.631298   \n",
      "2        0.430136         0.534857       0.023074 -0.631298   \n",
      "3        0.153275         0.771388       0.428338 -1.020897   \n",
      "4        0.153275        -1.002590       0.428338 -1.020897   \n",
      "\n",
      "   TEXTURE_USDA_encoded      prec  elevation_scaled     tmean    trange  \n",
      "0              0.737545  3.782619         -1.221677 -0.792786 -1.908889  \n",
      "1             -0.074938  0.084922          0.499363 -0.337188 -0.914481  \n",
      "2             -0.074938  0.380618          3.055712 -1.835239 -0.022087  \n",
      "3              0.737545 -0.943846         -0.252101  1.135902  0.047433  \n",
      "4              0.737545 -0.931629         -0.304104  1.107084 -0.154453  \n",
      "✅ SMOTE appliqué :\n",
      "Distribution des classes après SMOTE : Counter({1: 112132, 0: 112132})\n",
      "✅ TOMEK Links appliqué :\n",
      "Distribution des classes après SMOTE + TOMEK : Counter({0: 112132, 1: 111619})\n",
      "✔ Dataset équilibré sauvegardé sous : C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_feature_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from collections import Counter\n",
    "\n",
    "# === 1. Charger le dataset final après feature engineering ===\n",
    "df = pd.read_csv(r\"C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_feature_final.csv\")\n",
    "\n",
    "# === 2. Séparer features et target ===\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "# === 3. Normaliser les features numériques ===\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(\"✅ Normalisation terminée. Aperçu :\")\n",
    "print(X_scaled.head())\n",
    "\n",
    "# === 4. Appliquer SMOTE (oversampling) ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_scaled, y)\n",
    "print(\"✅ SMOTE appliqué :\")\n",
    "print(\"Distribution des classes après SMOTE :\", Counter(y_smote))\n",
    "\n",
    "# === 5. Appliquer TOMEK Links (undersampling) ===\n",
    "tomek = TomekLinks()\n",
    "X_tomek, y_tomek = tomek.fit_resample(X_smote, y_smote)\n",
    "print(\"✅ TOMEK Links appliqué :\")\n",
    "print(\"Distribution des classes après SMOTE + TOMEK :\", Counter(y_tomek))\n",
    "\n",
    "# === 6. Créer un DataFrame final équilibré ===\n",
    "df_final = pd.DataFrame(X_tomek, columns=X.columns)\n",
    "df_final['class'] = y_tomek\n",
    "\n",
    "# === 7. Sauvegarder le dataset équilibré ===\n",
    "output_file = r\"C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_feature_balanced.csv\"\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"✔ Dataset équilibré sauvegardé sous : {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5346d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution des classes ===\n",
      "non-fire: 112132 instances (50.11%)\n",
      "fire: 111619 instances (49.89%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le dataset final (ou équilibré)\n",
    "df = pd.read_csv(r\"C:\\Users\\pc\\Desktop\\DM\\datasets\\merged_feature_balanced.csv\")\n",
    "\n",
    "# Compter les occurrences\n",
    "class_counts = df['class'].value_counts()\n",
    "total = len(df)\n",
    "\n",
    "# Afficher le nombre et le pourcentage\n",
    "print(\"=== Distribution des classes ===\")\n",
    "for cls, count in class_counts.items():\n",
    "    percent = (count / total) * 100\n",
    "    label = \"fire\" if cls == 1 else \"non-fire\"\n",
    "    print(f\"{label}: {count} instances ({percent:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
